{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVNN_paper.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FxiNN2sNHSxa",
        "q2CSEN1cgnK-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzVJsLt1bmfm"
      },
      "source": [
        "## The setup of Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6GVdMghb0bd"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlw1GfSJgYd9"
      },
      "source": [
        "!pip install torch==1.7.1\n",
        "pip install complexPyTorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Input"
      ],
      "metadata": {
        "id": "FxiNN2sNHSxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#choose radar data formats\n",
        "input = 'range-time' # or 'range-doppler', 'spectrograms'"
      ],
      "metadata": {
        "id": "tDfDmjaUHR_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Load Data\"\"\"\n",
        "if input == 'rang-time':\n",
        "  data_path = 'rt_complex2.npy' # just add your path of range-time dataset (rt_complex2.npy)\n",
        "if input == 'range-doppler':\n",
        "  data_path = 'rd_complex2.npy' # just add your path of range-doppler dataset (rd_complex2.npy) \n",
        "if input == 'spectrograms':\n",
        "  data_path = 'spec_complex2.npy' # just add your path of spectrograms dataset (spec_complex2.npy)\n",
        "arr_df = np.load(data_path)\n",
        "X = arr_df[:,:-1]\n",
        "Y_onehot = arr_df[:,-1] - 1\n",
        "arr_X = X.reshape(X.shape[0],-1,240)\n",
        "arr_X = arr_X.swapaxes(1,2)\n",
        "print(f\"input is {input} 15-people data\")"
      ],
      "metadata": {
        "id": "pUfOiTL3HWqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_index = random.sample(range(arr_X.shape[0]), int(arr_X.shape[0]*0.8))\n",
        "test_index = [i for i in range(arr_X.shape[0]) if i not in train_index]"
      ],
      "metadata": {
        "id": "MKjPcpNEHZMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2CSEN1cgnK-"
      },
      "source": [
        "## Complex Blocks and Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAwgAobTgnnC"
      },
      "source": [
        "## Complex Blocks\n",
        "class ComplexConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=1, dilation=1, groups=1, bias=True):\n",
        "        super(ComplexConv,self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.padding = padding\n",
        "\n",
        "        ## Model components\n",
        "        self.conv_re = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "        self.conv_im = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "        \n",
        "    def forward(self, x): # shpae of x : [batch,2,channel,axis1,axis2]\n",
        "        real = self.conv_re(x[:,0]) - self.conv_im(x[:,1])\n",
        "        imaginary = self.conv_re(x[:,1]) + self.conv_im(x[:,0])\n",
        "        output = torch.stack((real,imaginary),dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyfREzWOguHe"
      },
      "source": [
        "class CReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CReLU,self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        ## Model components\n",
        "        self.relu_re = nn.ReLU()\n",
        "        self.relu_im = nn.ReLU()\n",
        "\n",
        "    def forward(self, x): # shpae of x : [batch,2,channel,axis1,axis2]\n",
        "        real = self.relu_re(x[:,0])\n",
        "        imaginary = self.relu_im(x[:,1])\n",
        "        output = torch.stack((real,imaginary),dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pUZpBtzguKY"
      },
      "source": [
        "class ComplexPool(nn.Module):\n",
        "    def __init__(self, kernel_size, stride=(1,1), padding=0, dilation=1):\n",
        "        super(ComplexPool,self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.padding = padding\n",
        "        self.pool_re = nn.MaxPool2d(kernel_size,stride, padding=padding)\n",
        "        self.pool_im = nn.MaxPool2d(kernel_size,stride,  padding=padding)\n",
        "        \n",
        "    def forward(self, x): # shpae of x : [batch,2,channel,axis1,axis2]\n",
        "        real = self.pool_re(x[:,0]) \n",
        "        imaginary =self.pool_im(x[:,1]) \n",
        "        output = torch.stack((real,imaginary),dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnJA19O4VVrD"
      },
      "source": [
        "class ComplexAdaptiveAvgPool2d(nn.Module):\n",
        "    def __init__(self, output_size = (1,1)):\n",
        "        super(ComplexAdaptiveAvgPool2d,self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.pool_re = nn.AdaptiveAvgPool2d(output_size)\n",
        "        self.pool_im = nn.AdaptiveAvgPool2d(output_size)\n",
        "        \n",
        "    def forward(self, x): # shpae of x : [batch,2,channel,axis1,axis2]\n",
        "        real = self.pool_re(x[:,0]) \n",
        "        imaginary = self.pool_im(x[:,1]) \n",
        "        output = torch.stack((real,imaginary),dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXE4M8n2gzpx"
      },
      "source": [
        "from complexPyTorch.complexLayers import ComplexBatchNorm2d\n",
        "class ComplexBN(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(ComplexBN,self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.bn = ComplexBatchNorm2d(num_features)\n",
        "        \n",
        "    def forward(self, x): # shpae of x : [batch,2,channel,axis1,axis2]\n",
        "        data_x = np.zeros([x.shape[0],x.shape[2],x.shape[3],x.shape[4]])\n",
        "        data_x = x[:,0,:,:,:].type(torch.complex64) + 1j*x[:,1,:,:,:].type(torch.complex64)\n",
        "        x = self.bn(data_x)\n",
        "        real = x.real\n",
        "        imaginary = x.imag\n",
        "        output = torch.stack((real,imaginary),dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVYda4BKhIPT"
      },
      "source": [
        "class shallow_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size=(4,4), stride = (2,2), padding=1)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features = 64*60*30, out_features = 2048)\n",
        "        self.fc2 = nn.Linear(2048, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.bn_1(self.conv1(x)))) #before flatten \n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhW8r0mCiWha"
      },
      "source": [
        "class shallow_ch2_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 64, kernel_size=(4,4), stride = (2,2), padding=1)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features = 64*60*30, out_features = 2048)\n",
        "        self.fc2 = nn.Linear(2048, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.bn_1(self.conv1(x)))) #before flatten \n",
        "        #print(x.shape)\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhxTk7CbhCEC"
      },
      "source": [
        "class deep_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size=(4,4), stride = (2,2), padding=1)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 64, (3,3),(1,1), padding=1)\n",
        "        self.bn_2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, (3,3),(1,1), padding=1)\n",
        "        self.bn_3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_4 = nn.BatchNorm2d(128)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,1))\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_5 = nn.BatchNorm2d(128)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size= (2, 2), stride = (1,1))      \n",
        "        '''\n",
        "        self.conv6 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_6 = nn.BatchNorm2d(128)\n",
        "        self.pool6 = nn.MaxPool2d(kernel_size= (2, 2), stride = (1,1))\n",
        "        \n",
        "        self.conv7 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_7 = nn.BatchNorm2d(128)\n",
        "        self.pool7 = nn.MaxPool2d(kernel_size= (2, 2), stride = (1,1))\n",
        "        '''\n",
        "        self.fc1 = nn.Linear(in_features = 128*8*7, out_features = 2048)\n",
        "        self.fc2 = nn.Linear(2048, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.bn_1(self.conv1(x)))) #before flatten \n",
        "        x = self.pool2(self.relu(self.bn_2(self.conv2(x)))) \n",
        "        x = self.pool3(self.relu(self.bn_3(self.conv3(x)))) \n",
        "        x = self.pool4(self.relu(self.bn_4(self.conv4(x))))\n",
        "        x = self.pool5(self.relu(self.bn_5(self.conv5(x)))) \n",
        "        #x = self.pool6(self.relu(self.bn_6(self.conv6(x)))) \n",
        "        #x = self.pool7(self.relu(self.bn_6(self.conv6(x)))) \n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4NlwX0niiNj"
      },
      "source": [
        "class deep_ch2_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 64, kernel_size=(4,4), stride = (2,2), padding=1)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "        self.relu = nn.ReLU()\n",
        "          \n",
        "        self.conv2 = nn.Conv2d(64, 64, (3,3),(1,1), padding=1)\n",
        "        self.bn_2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "    \n",
        "        self.conv3 = nn.Conv2d(64, 128, (3,3),(1,1), padding=1)\n",
        "        self.bn_3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,2))\n",
        "   \n",
        "        self.conv4 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_4 = nn.BatchNorm2d(128)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size= (2, 2), stride = (2,1))\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_5 = nn.BatchNorm2d(128)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size= (2, 2), stride = (1,1))\n",
        "        \n",
        "        '''\n",
        "        self.conv6 = nn.Conv2d(128, 128, (2,2),(1,1), padding=1)\n",
        "        self.bn_6 = nn.BatchNorm2d(128)\n",
        "        self.pool6 = nn.MaxPool2d(kernel_size= (2, 2), stride = (1,1))\n",
        "        '''\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features = 128*8*7, out_features = 2048)\n",
        "        self.fc2 = nn.Linear(2048, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.bn_1(self.conv1(x)))) #before flatten \n",
        "        x = self.pool2(self.relu(self.bn_2(self.conv2(x)))) \n",
        "        x = self.pool3(self.relu(self.bn_3(self.conv3(x)))) \n",
        "        x = self.pool4(self.relu(self.bn_4(self.conv4(x)))) \n",
        "        x = self.pool5(self.relu(self.bn_5(self.conv5(x)))) \n",
        "        #x = self.pool6(self.relu(self.bn_6(self.conv6(x)))) \n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z9CfFgChyH8"
      },
      "source": [
        "class shallow_Complex_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = ComplexConv(in_channels = 1, out_channels = 64, kernel_size=(4,4), stride = (2,2))\n",
        "        self.bn_1 = ComplexBN(64)\n",
        "        self.pool1 = ComplexPool(kernel_size= (2, 2), stride = (2,2))\n",
        "        self.relu = CReLU()\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features = 2*64*60*30, out_features = 2048)\n",
        "        self.fc2 = nn.Linear(2048, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.bn_1(self.conv1(x)))) #before flatten 2, 64, 60, 30  \n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOrAV31hyS0"
      },
      "source": [
        "class deep_Complex_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = ComplexConv(in_channels = 1, out_channels = 64, kernel_size=(4,4), stride = (2,2))\n",
        "        self.bn_1 = ComplexBN(64)\n",
        "        self.pool1 = ComplexPool(kernel_size= (2, 2), stride = (2,2))\n",
        "        self.relu = CReLU()\n",
        "        \n",
        "        self.conv2 = ComplexConv(64, 64, (3,3),(1,1))\n",
        "        self.bn_2 = ComplexBN(64)\n",
        "        self.pool2 = ComplexPool(kernel_size= (2, 2), stride = (2,2))\n",
        "        \n",
        "        self.conv3 = ComplexConv(64, 128, (3,3),(1,1))\n",
        "        self.bn_3 = ComplexBN(128)\n",
        "        self.pool3 = ComplexPool(kernel_size= (2, 2), stride = (2,2))\n",
        "        \n",
        "        self.conv4 = ComplexConv(128, 128, (2,2),(1,1))\n",
        "        self.bn_4 = ComplexBN(128)\n",
        "        self.pool4 = ComplexPool(kernel_size= (2, 2), stride = (2,1))\n",
        "        \n",
        "        self.conv5 = ComplexConv(128, 128, (2,2),(1,1))\n",
        "        self.bn_5 = ComplexBN(128)\n",
        "        self.pool5 = ComplexPool(kernel_size= (2, 2), stride = (1,1))\n",
        "        '''\n",
        "        self.conv6 = ComplexConv(128, 128, (2,2),(1,1))\n",
        "        self.bn_6 = ComplexBN(128)\n",
        "        self.pool6 = ComplexPool(kernel_size= (2, 2), stride = (1,1))\n",
        "        \n",
        "        self.conv7 = ComplexConv(128, 128, (2,2),(1,1))\n",
        "        self.bn_7 = ComplexBN(128)\n",
        "        self.pool7 = ComplexPool(kernel_size= (2, 2), stride = (1,1))\n",
        "        '''\n",
        "        self.fc1 = nn.Linear(in_features = 2*128*8*7, out_features = 2048)\n",
        "        self.fc2 = nn.Linear(2048, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.bn_1(self.conv1(x)))) #before flatten \n",
        "        x = self.pool2(self.relu(self.bn_2(self.conv2(x)))) \n",
        "        x = self.pool3(self.relu(self.bn_3(self.conv3(x)))) \n",
        "        x = self.pool4(self.relu(self.bn_4(self.conv4(x)))) \n",
        "        x = self.pool5(self.relu(self.bn_5(self.conv5(x)))) \n",
        "        #x = self.pool6(self.relu(self.bn_6(self.conv6(x))))\n",
        "        #x = self.pool7(self.relu(self.bn_6(self.conv6(x)))) \n",
        "        #print(x.shape)\n",
        "  \n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOR3JO4NkFGI"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HUq45_Y8p-b"
      },
      "source": [
        "class ResNet_complex(nn.Module):\n",
        "  def __init__(\n",
        "        self, num_classes: int = 9\n",
        "        ):\n",
        "        super(ResNet_complex, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = ComplexConv(in_channels = 1, out_channels = 64, kernel_size=(7,7), stride = (2,2), padding=3)\n",
        "        self.bn1 = ComplexBN(64)\n",
        "        self.relu = CReLU()\n",
        "        self.pool1 = ComplexPool(kernel_size= (3, 3), stride = (2,2), padding=1)\n",
        "\n",
        "        self.res11 = nn.Sequential(*self.make_res_block(64, 64, stride=(1,1)))\n",
        "        self.res12 = nn.Sequential(*self.make_res_block(64, 64, stride=(1,1)))\n",
        "\n",
        "        self.res21 = nn.Sequential(*self.make_res_block(64, 128, stride=(2,2)))\n",
        "        self.res22 = nn.Sequential(*self.make_res_block(128, 128, stride=(1,1)))\n",
        "        self.downsample2 = ComplexConv(64, 128, (1, 1), stride = (2,2), padding=0)\n",
        "\n",
        "        self.res31 = nn.Sequential(*self.make_res_block(128, 256, stride=(2,2)))\n",
        "        self.res32 = nn.Sequential(*self.make_res_block(256, 256, stride=(1,1)))\n",
        "        self.downsample3 = ComplexConv(128, 256, (1, 1), stride = (2,2), padding=0)\n",
        "\n",
        "        self.res41 = nn.Sequential(*self.make_res_block(256, 512, stride=(2,2)))\n",
        "        self.res42 = nn.Sequential(*self.make_res_block(512, 512, stride=(1,1)))\n",
        "        self.downsample4 = ComplexConv(256, 512, (1, 1), stride = (2,2), padding=0)\n",
        "\n",
        "        self.avgpool = ComplexAdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512*2, num_classes) #\n",
        "        \n",
        "  def make_res_block(self, in_channel, out_channel, stride):  \n",
        "      res_block = []\n",
        "      res_block.append(ComplexConv(in_channel, out_channel, kernel_size=(3,3), stride=stride, padding=1, groups=1, bias=False, dilation=1))\n",
        "      res_block.append(ComplexBN(out_channel))\n",
        "      res_block.append(CReLU())\n",
        "      res_block.append(ComplexConv(out_channel, out_channel, kernel_size=(3,3), padding=1, groups=1, bias=False, dilation=1))\n",
        "      res_block.append(ComplexBN(out_channel))\n",
        "      return res_block\n",
        "      \n",
        "  def forward(self, x):\n",
        "     x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n",
        "     # building block 1\n",
        "     x = x + self.res11(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res12(x)\n",
        "     x = self.relu(x)\n",
        "     # building block 2\n",
        "     x = self.downsample2(x) + self.res21(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res22(x)\n",
        "     x = self.relu(x)\n",
        "     # building block 3\n",
        "     x = self.downsample3(x) + self.res31(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res32(x)\n",
        "     x = self.relu(x)\n",
        "     # building block 4\n",
        "     x = self.downsample4(x) + self.res41(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res42(x)\n",
        "     x = self.relu(x)\n",
        "     \n",
        "     x = self.avgpool(x)\n",
        "     #print(x.shape)\n",
        "     x = torch.flatten(x, 1)\n",
        "     x = self.fc(x)\n",
        "     return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDSQVFAXTz6l"
      },
      "source": [
        "class ResNet18(nn.Module):\n",
        "  def __init__(\n",
        "        self,\n",
        "        in_channels = 1,\n",
        "        num_classes: int = 9\n",
        "        ):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 64, kernel_size=(7,7), stride = (2,2), padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size= (3, 3), stride = (2,2), padding=1)\n",
        "\n",
        "        self.res11 = nn.Sequential(*self.make_res_block(64, 64, stride=(1,1)))\n",
        "        self.res12 = nn.Sequential(*self.make_res_block(64, 64, stride=(1,1)))\n",
        "\n",
        "        self.res21 = nn.Sequential(*self.make_res_block(64, 128, stride=(2,2)))\n",
        "        self.res22 = nn.Sequential(*self.make_res_block(128, 128, stride=(1,1)))\n",
        "        self.downsample2 = nn.Conv2d(64, 128, (1, 1), stride = (2,2))\n",
        "\n",
        "        self.res31 = nn.Sequential(*self.make_res_block(128, 256, stride=(2,2)))\n",
        "        self.res32 = nn.Sequential(*self.make_res_block(256, 256, stride=(1,1)))\n",
        "        self.downsample3 = nn.Conv2d(128, 256, (1, 1), stride = (2,2))\n",
        "\n",
        "        self.res41 = nn.Sequential(*self.make_res_block(256, 512, stride=(2,2)))\n",
        "        self.res42 = nn.Sequential(*self.make_res_block(512, 512, stride=(1,1)))\n",
        "        self.downsample4 = nn.Conv2d(256, 512, (1, 1), stride = (2,2))\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes) #\n",
        "\n",
        "  def make_res_block(self, in_channel, out_channel, stride):\n",
        "        res_block = []\n",
        "        res_block.append(nn.Conv2d(in_channel, out_channel, kernel_size=(3,3), stride=stride, padding=1, groups=1, bias=False, dilation=1))\n",
        "        res_block.append(nn.BatchNorm2d(out_channel))\n",
        "        res_block.append(nn.ReLU(inplace=True))\n",
        "        res_block.append(nn.Conv2d(out_channel, out_channel, kernel_size=(3,3), padding=1, groups=1, bias=False, dilation=1))\n",
        "        res_block.append(nn.BatchNorm2d(out_channel))\n",
        "        return res_block\n",
        "    \n",
        "  def forward(self, x):\n",
        "     x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n",
        "     # building block 1\n",
        "     x = x + self.res11(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res12(x)\n",
        "     x = self.relu(x)\n",
        "     # building block 2\n",
        "     x = self.downsample2(x) + self.res21(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res22(x)\n",
        "     x = self.relu(x)\n",
        "     # building block 3\n",
        "     x = self.downsample3(x) + self.res31(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res32(x)\n",
        "     x = self.relu(x)\n",
        "     # building block 4\n",
        "     x = self.downsample4(x) + self.res41(x)\n",
        "     x = self.relu(x)\n",
        "     x = x + self.res42(x)\n",
        "     x = self.relu(x)\n",
        "     \n",
        "     x = self.avgpool(x)\n",
        "     #print(x.shape)\n",
        "     x = torch.flatten(x, 1)\n",
        "     x = self.fc(x)\n",
        "     return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvN-LBGxcYsC"
      },
      "source": [
        "## programme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Ql8us8k1eX"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, epoch, final_epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    train_acc = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch == final_epoch:\n",
        "      print(f\"epoch: {epoch}--Train accuracy is: {(100*train_acc/size):>0.1f}%\")\n",
        "    return train_acc/size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_16YKt5lBY3"
      },
      "source": [
        "def test(dataloader, model, loss_fn, epoch, final_epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    if epoch == final_epoch:\n",
        "      test_loss /= num_batches\n",
        "      correct /= size\n",
        "      print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    return correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtfajuUZlOf0"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "def adjust_learning_rate(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJH-RxNvcYXN"
      },
      "source": [
        "for i in range(4):\n",
        "  if i == 0:\n",
        "    # multi-channel (abs): num*1*240*120\n",
        "    data_x = np.zeros([arr_X.shape[0],1,arr_X.shape[1],int(arr_X.shape[2]/2)])\n",
        "    data_x[:,0,:,:] =  abs(arr_X[:,:,:int(arr_X.shape[2]/2)] + 1j*arr_X[:,:,int(arr_X.shape[2]/2):])\n",
        "    print(\"----Tradtional CNN: abs only (real number)-----\")\n",
        "  if i == 1:\n",
        "    # multi-channel (abs&phase): num*2*240*120\n",
        "    data_x = np.zeros([arr_X.shape[0],2,arr_X.shape[1],int(arr_X.shape[2]/2)])\n",
        "    data_x[:,0,:,:] =  np.abs(arr_X[:,:,:int(arr_X.shape[2]/2)] + 1j*arr_X[:,:,int(arr_X.shape[2]/2):]) \n",
        "    data_x[:,1,:,:] =  np.angle(arr_X[:,:,:int(arr_X.shape[2]/2)] + 1j*arr_X[:,:,int(arr_X.shape[2]/2):]) \n",
        "    print(\"----CVNN Multichannel: Abs and phase----\")\n",
        "  if i == 2:\n",
        "    # multi-channel (real & imag): num*2*240*120\n",
        "    data_x = np.zeros([arr_X.shape[0],2,arr_X.shape[1],int(arr_X.shape[2]/2)])\n",
        "    data_x[:,0,:,:] =  arr_X[:,:,:int(arr_X.shape[2]/2)] \n",
        "    data_x[:,1,:,:] =  arr_X[:,:,int(arr_X.shape[2]/2):]\n",
        "    print(\"----CVNN Multichannel: Real and imaginary----\")\n",
        "  if i == 3:\n",
        "    # DCN\n",
        "    data_x = np.zeros([arr_X.shape[0],2,1, arr_X.shape[1], int(arr_X.shape[2]/2)])\n",
        "    data_x[:,0,:,:,:] = arr_X[:,:,:int(arr_X.shape[2]/2)].reshape(data_x[:, 0,...].shape) #X_real\n",
        "    data_x[:,1,:,:,:] = arr_X[:,:,int(arr_X.shape[2]/2):].reshape(data_x[:, 0,...].shape) #X_imag\n",
        "    print(\"----CVNN DCN (Deep complex networks)----\")\n",
        "  Xtrain = data_x[train_index,...]\n",
        "  Ytrain = Y_onehot[train_index,...]\n",
        "  Xtest = data_x[test_index,...]\n",
        "  Ytest = Y_onehot[test_index,...]\n",
        "  data_train = torch.utils.data.TensorDataset(torch.from_numpy(Xtrain).type(torch.FloatTensor), torch.from_numpy (Ytrain).type(torch.LongTensor))\n",
        "  data_test = torch.utils.data.TensorDataset(torch.from_numpy(Xtest).type(torch.FloatTensor), torch.from_numpy (Ytest).type(torch.LongTensor))\n",
        "  batch_size = 32\n",
        "  # Create data loaders.\n",
        "  train_dataloader = DataLoader(data_train, batch_size=batch_size)\n",
        "  test_dataloader = DataLoader(data_test, batch_size=batch_size)\n",
        "  for k in range(3):\n",
        "    if k == 0:\n",
        "      print(f\"model is plain shallow CNN (one Building Layer)\")\n",
        "      if i == 0:\n",
        "        model = shallow_Net().to(device)\n",
        "      else:\n",
        "        if i == 3:\n",
        "          model = shallow_Complex_Net().to(device)\n",
        "        else:\n",
        "          model = shallow_ch2_Net().to(device)\n",
        "    if k == 1:\n",
        "      print(f\"model is plain deep CNN (five Building Layers)\")\n",
        "      if i == 0:\n",
        "        model = deep_Net().to(device)\n",
        "      else:\n",
        "        if i == 3:\n",
        "          model = deep_Complex_Net().to(device)\n",
        "        else:\n",
        "          model = deep_ch2_Net().to(device)\n",
        "    if k == 2:\n",
        "      print(f\"model is ResNet18\")\n",
        "      if i == 0:\n",
        "        model = ResNet18(in_channels = 1).to(device)\n",
        "      else:\n",
        "        if i == 3:\n",
        "          model = ResNet_complex().to(device)\n",
        "        else:\n",
        "          model = ResNet18(in_channels = 2).to(device)\n",
        "    epochs = 45\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
        "    for t in range(epochs):\n",
        "      lr = 1e-4\n",
        "      if t > 30:\n",
        "        if t < 40:\n",
        "          lr = 1e-5\n",
        "        else:\n",
        "          lr = 1e-6*5\n",
        "      adjust_learning_rate(optimizer, lr)\n",
        "      train(train_dataloader, model, loss_fn, optimizer, t, epochs-1)\n",
        "      test(test_dataloader, model, loss_fn, t, epochs-1)\n",
        "    print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}